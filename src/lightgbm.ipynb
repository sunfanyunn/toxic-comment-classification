{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal of this kernel is to demonstrate that LightGBM can have predictive\n",
    "# performance in line with that of a logistic regression. The theory is that\n",
    "# labeling is being driven by a few keywords that can be picked up by trees.\n",
    "#\n",
    "# With some careful tuning, patience with runtimes, and additional feature\n",
    "# engineering, this kernel can be tuned to slightly exceed the best\n",
    "# logistic regression. Best of all, the two approaches (LR and LGB) blend\n",
    "# well together.\n",
    "#\n",
    "# Hopefully, with some work, this could be a good addition to your ensemble.\n",
    "\n",
    "import gc\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('../input/internal_train.csv').fillna(' ')\n",
    "test = pd.read_csv('../input/internal_test.csv').fillna(' ')\n",
    "print('Loaded')\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word TFIDF 1/2\n",
      "Word TFIDF 2/2\n",
      "Char Count 1/2\n",
      "Char Count 2/2\n",
      "HStack 1/2\n",
      "HStack 2/2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=50000)\n",
    "train_word_features = word_vectorizer.fit_transform(train_text)\n",
    "print('Word TFIDF 1/2')\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "print('Word TFIDF 2/2')\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=50000)\n",
    "\n",
    "train_char_features = char_vectorizer.fit_transform(train_text)\n",
    "print('Char Count 1/2')\n",
    "test_char_features = char_vectorizer.transform(test_text)\n",
    "print('Char Count 2/2')\n",
    "\n",
    "train_features = hstack([ train_char_features, train_word_features])\n",
    "print('HStack 1/2')\n",
    "test_features = hstack([ test_char_features, test_word_features])\n",
    "print('HStack 2/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count 1/2\n",
      "Word Count 2/2\n",
      "Char Count 1/2\n",
      "Char Count 2/2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "word_vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=50000)\n",
    "\n",
    "train_word_features = word_vectorizer.fit_transform(train_text)\n",
    "print('Word Count 1/2')\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "print('Word Count 2/2')\n",
    "\n",
    "char_vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=50000)\n",
    "train_char_features = char_vectorizer.fit_transform(train_text)\n",
    "print('Char Count 1/2')\n",
    "test_char_features = char_vectorizer.transform(test_text)\n",
    "print('Char Count 2/2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79785, 100000)\n",
      "(79786, 100000)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HStack 1/2\n",
      "HStack 2/2\n"
     ]
    }
   ],
   "source": [
    "train_features = hstack([ train_features, train_char_features, train_word_features])\n",
    "print('HStack 1/2')\n",
    "test_features = hstack([ test_features, test_char_features, test_word_features])\n",
    "print('HStack 2/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "\n",
    "train.drop('comment_text', axis=1, inplace=True)\n",
    "del test\n",
    "del train_text\n",
    "del test_text\n",
    "del train_char_features\n",
    "del test_char_features\n",
    "del train_word_features\n",
    "del test_word_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "Train: before feature selection's shape:  (79785, 200000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willy/ENV/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (79785, 30416)\n",
      "Test: before feature selection's shape: (79786, 200000)\n",
      "After (79786, 30416)\n",
      "severe_toxic\n",
      "Train: before feature selection's shape:  (79785, 200000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willy/ENV/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (79785, 28462)\n",
      "Test: before feature selection's shape: (79786, 200000)\n",
      "After (79786, 28462)\n",
      "obscene\n",
      "Train: before feature selection's shape:  (79785, 200000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willy/ENV/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (79785, 28905)\n",
      "Test: before feature selection's shape: (79786, 200000)\n",
      "After (79786, 28905)\n",
      "threat\n",
      "Train: before feature selection's shape:  (79785, 200000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willy/ENV/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (79785, 27630)\n",
      "Test: before feature selection's shape: (79786, 200000)\n",
      "After (79786, 27630)\n",
      "insult\n",
      "Train: before feature selection's shape:  (79785, 200000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willy/ENV/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (79785, 28616)\n",
      "Test: before feature selection's shape: (79786, 200000)\n",
      "After (79786, 28616)\n",
      "identity_hate\n",
      "Train: before feature selection's shape:  (79785, 200000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willy/ENV/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (79785, 27381)\n",
      "Test: before feature selection's shape: (79786, 200000)\n",
      "After (79786, 27381)\n"
     ]
    }
   ],
   "source": [
    "all_train_sparse_matrix = {}\n",
    "all_test_sparse_matrix = {}\n",
    "\n",
    "for class_name in class_names:\n",
    "    print(class_name)\n",
    "    train_target = train[class_name]\n",
    "    model = LogisticRegression(solver='sag')\n",
    "    sfm = SelectFromModel(model)\n",
    "    \n",
    "    print('Train: before feature selection\\'s shape: ', train_features.shape)\n",
    "    train_sparse_matrix = sfm.fit_transform(train_features, train_target)\n",
    "    print('After', train_sparse_matrix.shape)\n",
    "    #train_sparse_matrix, valid_sparse_matrix, y_train, y_valid = train_test_split(train_sparse_matrix, train_target, test_size=0.05, random_state=144)\n",
    "    print('Test: before feature selection\\'s shape:', test_features.shape)\n",
    "    test_sparse_matrix = sfm.transform(test_features)\n",
    "    print('After', test_sparse_matrix.shape)\n",
    "    \n",
    "    all_train_sparse_matrix[class_name] = train_sparse_matrix\n",
    "    all_test_sparse_matrix[class_name] = test_sparse_matrix\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "[10]\tcv_agg's auc: 0.934606 + 0.00258363\n",
      "[20]\tcv_agg's auc: 0.950412 + 0.00362118\n",
      "[30]\tcv_agg's auc: 0.959527 + 0.00312989\n",
      "[40]\tcv_agg's auc: 0.96463 + 0.00271708\n",
      "[50]\tcv_agg's auc: 0.966909 + 0.00218623\n",
      "[60]\tcv_agg's auc: 0.968307 + 0.00229625\n",
      "[70]\tcv_agg's auc: 0.968768 + 0.00217757\n",
      "[80]\tcv_agg's auc: 0.969036 + 0.00203142\n",
      "[90]\tcv_agg's auc: 0.969091 + 0.00188448\n",
      "[100]\tcv_agg's auc: 0.96939 + 0.0018902\n",
      "[110]\tcv_agg's auc: 0.969484 + 0.00182103\n",
      "[120]\tcv_agg's auc: 0.96937 + 0.00175764\n",
      "[130]\tcv_agg's auc: 0.969392 + 0.00170366\n",
      "[140]\tcv_agg's auc: 0.969325 + 0.00168527\n",
      "111\n",
      "[0.96951737056053966]\n",
      "final score: 0.969517370561\n",
      "severe_toxic\n",
      "[10]\tcv_agg's auc: 0.94653 + 0.0210525\n",
      "[20]\tcv_agg's auc: 0.978567 + 0.00553647\n",
      "[30]\tcv_agg's auc: 0.980923 + 0.00520922\n",
      "[40]\tcv_agg's auc: 0.981548 + 0.0064798\n",
      "[50]\tcv_agg's auc: 0.981743 + 0.00565448\n",
      "45\n",
      "[0.96951737056053966, 0.98211140695457044]\n",
      "final score: 0.975814388758\n",
      "obscene\n",
      "[10]\tcv_agg's auc: 0.974065 + 0.00235525\n",
      "[20]\tcv_agg's auc: 0.984387 + 0.00147523\n",
      "[30]\tcv_agg's auc: 0.987044 + 0.000982844\n",
      "[40]\tcv_agg's auc: 0.988148 + 0.00106736\n",
      "[50]\tcv_agg's auc: 0.98851 + 0.000888293\n",
      "[60]\tcv_agg's auc: 0.988677 + 0.000799274\n",
      "[70]\tcv_agg's auc: 0.988785 + 0.000627633\n",
      "[80]\tcv_agg's auc: 0.988858 + 0.000693063\n",
      "76\n",
      "[0.96951737056053966, 0.98211140695457044, 0.98886729693443576]\n",
      "final score: 0.98016535815\n",
      "threat\n",
      "[10]\tcv_agg's auc: 0.870459 + 0.0143368\n",
      "[20]\tcv_agg's auc: 0.945651 + 0.0207992\n",
      "[30]\tcv_agg's auc: 0.968071 + 0.0141924\n",
      "[40]\tcv_agg's auc: 0.974394 + 0.0137953\n",
      "[50]\tcv_agg's auc: 0.978308 + 0.0101749\n",
      "[60]\tcv_agg's auc: 0.979726 + 0.00928306\n",
      "[70]\tcv_agg's auc: 0.979965 + 0.00853336\n",
      "[80]\tcv_agg's auc: 0.980531 + 0.00787658\n",
      "79\n",
      "[0.96951737056053966, 0.98211140695457044, 0.98886729693443576, 0.98053120700021279]\n",
      "final score: 0.980256820362\n",
      "insult\n",
      "[10]\tcv_agg's auc: 0.950849 + 0.00380153\n",
      "[20]\tcv_agg's auc: 0.968616 + 0.00191151\n",
      "[30]\tcv_agg's auc: 0.973927 + 0.00200094\n",
      "[40]\tcv_agg's auc: 0.976344 + 0.002282\n",
      "[50]\tcv_agg's auc: 0.977237 + 0.00202643\n",
      "[60]\tcv_agg's auc: 0.977493 + 0.00192358\n",
      "[70]\tcv_agg's auc: 0.977152 + 0.00196182\n",
      "57\n",
      "[0.96951737056053966, 0.98211140695457044, 0.98886729693443576, 0.98053120700021279, 0.97755344544664236]\n",
      "final score: 0.979716145379\n",
      "identity_hate\n",
      "[10]\tcv_agg's auc: 0.892846 + 0.0242496\n",
      "[20]\tcv_agg's auc: 0.940712 + 0.0155119\n",
      "[30]\tcv_agg's auc: 0.961526 + 0.00674157\n",
      "[40]\tcv_agg's auc: 0.966466 + 0.00789838\n",
      "[50]\tcv_agg's auc: 0.967182 + 0.00743465\n",
      "[60]\tcv_agg's auc: 0.966898 + 0.00735496\n",
      "[70]\tcv_agg's auc: 0.967679 + 0.00655417\n",
      "[80]\tcv_agg's auc: 0.966231 + 0.00736537\n",
      "69\n",
      "[0.96951737056053966, 0.98211140695457044, 0.98886729693443576, 0.98053120700021279, 0.97755344544664236, 0.96767871792473381]\n",
      "final score: 0.97770990747\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "params = {'learning_rate': 0.2,\n",
    "              'application': 'binary',\n",
    "              'num_leaves': 31,\n",
    "              'verbosity': -1,\n",
    "              'metric': 'auc',\n",
    "              'data_random_seed': 2,\n",
    "              'bagging_fraction': 0.8,\n",
    "              'feature_fraction': 0.6,\n",
    "              'nthread': 4,\n",
    "              'lambda_l1': 1,\n",
    "              'lambda_l2': 1}\n",
    "\n",
    "rounds_lookup = {'toxic': 140,\n",
    "                 'severe_toxic': 50,\n",
    "                 'obscene': 80,\n",
    "                 'threat': 80,\n",
    "                 'insult': 70,\n",
    "                 'identity_hate': 80}\n",
    "\n",
    "final_val_score = []\n",
    "for class_name in class_names:\n",
    "    print(class_name)\n",
    "    train_sparse_matrix = all_train_sparse_matrix[class_name].astype(np.float32)\n",
    "    test_sparse_matrix = all_test_sparse_matrix[class_name].astype(np.float32)\n",
    "    \n",
    "    y_train = train[class_name]\n",
    "    d_train = lgb.Dataset(train_sparse_matrix, label=y_train.astype(np.float32))\n",
    "    \n",
    "    res = lgb.cv(params,\n",
    "                 train_set=d_train,\n",
    "                 num_boost_round=rounds_lookup[class_name],\n",
    "                 verbose_eval=10)\n",
    "    \n",
    "    rounds = np.argmax(res['auc-mean'])\n",
    "    final_val_score.append(res['auc-mean'][rounds])\n",
    "    print(rounds)\n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=rounds,\n",
    "                      verbose_eval=10)\n",
    "    \n",
    "    submission[class_name] = model.predict(test_sparse_matrix)\n",
    "\n",
    "    print(final_val_score)\n",
    "    print('final score:', np.mean(final_val_score))\n",
    "submission.to_csv('lgb_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
